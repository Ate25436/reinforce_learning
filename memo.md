# TCG 強化学習

## 報酬

### 基本

- 勝敗がついたとき，勝者に1，敗者に-1

### Play

- 不能な操作 ... 操作者に-0.01

### attack

- 不能な操作 ... 操作者に-0.01

### end_turn

- 報酬なし

## agent_1の行動指針

- play
  1. プレイできるカードを，マナレシオが高い順に並べる
  2. マナレシオが高い順に，プレイできるならプレイする
- attack
  - aggro
    - とりあえず顔を殴る
  - control
    - 相手の場にこちらが不利トレードしなくて済む（相手の攻撃力より自分の体力のほうが高い場合）はそのカードに攻撃
    - いない場合は相手の顔を殴る

## ToDo

- [X] 2つのベースモデルを比較する（もし結果が離れていたらt検定）
  - [X] 勝率
- [X] punishありモデルを作成
- [X] punishありも性能測定する
  - [X] 勝率
  - [X] 測定時間

## 日記

- 2025/02/24

  - 不能な操作に対してバツを与える環境とそうでない環境で勝率・対戦時間の変化を見た．
  - なぜか，バツを与える環境のほうが対戦時間が長くなった．
- 2025/03/2

  - デッキを構築する操作も追加した．
  - 本来はカード0が最も強いのでカード0が最も多く入っているはずだがカード39が一番多く入っていた

  →ターン終了の行動値が39なのでそれが影響している可能性
- 2025/04/13

  - turn_endを0にした

  →37が最も多くなった
- 2025/05/23
  - baseモデルはpotential_base_2に決定